generate data ========================================================================

import numpy as np
import pandas as pd

# Function to generate synthetic data
def make_classification_simple(n_samples=1000, n_features=2, n_classes=2, class_sep=1.0, random_state=None):
    """
    Generate a simple synthetic dataset for classification with shuffled data.
    
    Parameters:
    - n_samples: Total number of data points.
    - n_features: Number of features.
    - n_classes: Number of classes.
    - class_sep: Distance between class centers.
    - random_state: Seed for reproducibility.
    
    Returns:
    - X: Shuffled feature matrix (n_samples x n_features).
    - y: Shuffled class labels (n_samples,).
    """
    if random_state:
        np.random.seed(random_state)

    # Determine samples per class
    samples_per_class = n_samples // n_classes
    remainder = n_samples % n_classes

    # Generate centroids for each class
    centroids = np.random.uniform(-10, 10, size=(n_classes, n_features))

    X, y = [], []

    for class_id, centroid in enumerate(centroids):
        n_points = samples_per_class + (1 if class_id < remainder else 0)
        
        # Points around centroid
        points = centroid + class_sep * np.random.randn(n_points, n_features)
        X.append(points)
        y.extend([class_id] * n_points)

    # Combine and shuffle the data
    X = np.vstack(X)
    y = np.array(y)
    
    # Shuffle the dataset
    indices = np.random.permutation(n_samples)
    X, y = X[indices], y[indices]

    return X, y

# Function to load dataset from a CSV file
def load_data_from_csv(file_path):
    """
    Load data from a CSV file. Assumes that the last column is the target variable.
    """
    data = pd.read_csv(file_path)
    
    # Assuming the last column is the target variable
    X = data.iloc[:, :-1].values  # Feature columns
    y = data.iloc[:, -1].values   # Target column (if exists)
    
    return X, y

X, y = make_classification_simple(n_samples=500, n_features=2, n_classes=3, class_sep=3.0, random_state=42)
X_train, X_test = X[:400], X[400:]
y_train, y_test = y[:400], y[400:]


KNN =====================================================================================================

# kNN from scratch
class KNN:
    def __init__(self, k=3):
        self.k = k

    def fit(self, X, y):
        self.X_train = X
        self.y_train = y

    def predict(self, X):
        y_pred = [self._predict(x) for x in X]
        return np.array(y_pred)

    def _predict(self, x):
        # Compute distances between x and all examples in the training set
        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]
        # Sort by distance and return indices of the first k neighbors
        k_idx = np.argsort(distances)[: self.k]
        # Extract the labels of the k nearest neighbor training samples
        k_neighbor_labels = [self.y_train[i] for i in k_idx]
        # return the most common class label
        most_common = Counter(k_neighbor_labels).most_common(1)
        return most_common[0][0]

def euclidean_distance(x1, x2):
    return np.sqrt(np.sum((x1 - x2) ** 2))

def accuracy(y_true, y_pred):
    accuracy = np.sum(y_true == y_pred) / len(y_true)
    return accuracy

def evaluate_k(X_train, y_train, X_test, y_test, max_k=20):
    accuracies = []
    k_values = range(1, max_k + 1)
    
    for k in k_values:
        clf = KNN(k=k)
        clf.fit(X_train, y_train)
        predictions = clf.predict(X_test)
        acc = accuracy(y_test, predictions)
        accuracies.append(acc)
    
    return k_values, accuracies

def plot_elbow(k_values, accuracies):
    plt.figure(figsize=(8, 6))
    plt.plot(k_values, accuracies, marker='o', linestyle='-', color='b')
    plt.title('KNN Elbow Method: Accuracy vs. k')
    plt.xlabel('Number of Neighbors (k)')
    plt.ylabel('Accuracy')
    plt.xticks(k_values)
    plt.grid()
    plt.show()

max_k = 10
k_values, accuracies = evaluate_k(X_train, y_train, X_test, y_test, max_k=max_k)
plot_elbow(k_values, accuracies)

k = 3
clf = KNN(k=k)
clf.fit(X_train, y_train)
predictions = clf.predict(X_test)
print("KNN classification accuracy", accuracy(y_test, predictions))

# Plot the decision boundary

def plot_decision_boundary(X, y, model, title):
    # Create a mesh grid
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))
    
    # Predict on the mesh grid
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    
    # Plot the decision boundary
    plt.contourf(xx, yy, Z, alpha=0.5, cmap=plt.cm.Paired)
    for class_label in np.unique(y):
        plt.scatter(X[y == class_label, 0], X[y == class_label, 1], label=f"Class {class_label}", edgecolor="k")
    plt.title(title)
    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")
    plt.legend()
    plt.grid(alpha=0.5)

# Visualize the decision boundary
plt.figure(figsize=(10, 6))
plot_decision_boundary(X, y, clf, title=f"KNN Decision Boundary (k={k})")
plt.show()

kMeans ==============================================================================================================

# kMeans from scratch
class KMeans:
    def __init__(self, K=5, max_iters=100, plot_steps=False):
        self.K = K
        self.max_iters = max_iters
        self.plot_steps = plot_steps

        # list of sample indices for each cluster
        self.clusters = [[] for _ in range(self.K)]
        # the centers (mean feature vector) for each cluster
        self.centroids = []

    def predict(self, X):
        self.X = X
        self.n_samples, self.n_features = X.shape

        # initialize
        random_sample_idxs = np.random.choice(self.n_samples, self.K, replace=False)
        self.centroids = [self.X[idx] for idx in random_sample_idxs]

        # Optimize clusters
        for _ in range(self.max_iters):
            # Assign samples to closest centroids (create clusters)
            self.clusters = self._create_clusters(self.centroids)

            if self.plot_steps:
                self.plot()

            # Calculate new centroids from the clusters
            centroids_old = self.centroids
            self.centroids = self._get_centroids(self.clusters)

            # check if clusters have changed
            if self._is_converged(centroids_old, self.centroids):
                break

            if self.plot_steps:
                self.plot()

        # Classify samples as the index of their clusters
        return self._get_cluster_labels(self.clusters)

    def _get_cluster_labels(self, clusters):
        # each sample will get the label of the cluster it was assigned to
        labels = np.empty(self.n_samples)

        for cluster_idx, cluster in enumerate(clusters):
            for sample_index in cluster:
                labels[sample_index] = cluster_idx
        return labels

    def _create_clusters(self, centroids):
        # Assign the samples to the closest centroids to create clusters
        clusters = [[] for _ in range(self.K)]
        for idx, sample in enumerate(self.X):
            centroid_idx = self._closest_centroid(sample, centroids)
            clusters[centroid_idx].append(idx)
        return clusters

    def _closest_centroid(self, sample, centroids):
        # distance of the current sample to each centroid
        distances = [euclidean_distance(sample, point) for point in centroids]
        closest_index = np.argmin(distances)
        return closest_index

    def _get_centroids(self, clusters):
        # assign mean value of clusters to centroids
        centroids = np.zeros((self.K, self.n_features))
        for cluster_idx, cluster in enumerate(clusters):
            cluster_mean = np.mean(self.X[cluster], axis=0)
            centroids[cluster_idx] = cluster_mean
        return centroids

    def _is_converged(self, centroids_old, centroids):
        # distances between each old and new centroids, fol all centroids
        distances = [
            euclidean_distance(centroids_old[i], centroids[i]) for i in range(self.K)
        ]
        return sum(distances) == 0

    def plot(self):
        fig, ax = plt.subplots(figsize=(12, 8))

        for i, index in enumerate(self.clusters):
            point = self.X[index].T
            ax.scatter(*point)

        for point in self.centroids:
            ax.scatter(*point, marker="x", color="black", linewidth=2)

        plt.show()

def euclidean_distance(x1, x2):
    return np.sqrt(np.sum((x1 - x2) ** 2))

def calculate_inertia(X, kmeans):
    """
    Calculate the inertia (sum of squared distances between points and their centroids).
    """
    inertia = 0
    for cluster_idx, cluster in enumerate(kmeans.clusters):
        cluster_points = X[cluster]
        centroid = kmeans.centroids[cluster_idx]
        distances = [euclidean_distance(point, centroid) for point in cluster_points]
        inertia += np.sum(np.square(distances))
    return inertia

def elbow_method(X, max_k=10):
    """
    Apply the elbow method to determine the optimal number of clusters.
    """
    inertias = []
    k_values = range(1, max_k + 1)

    for k in k_values:
        kmeans = KMeans(K=k, max_iters=150, plot_steps=False)
        kmeans.predict(X)
        inertia = calculate_inertia(X, kmeans)
        inertias.append(inertia)

    # Plotting the elbow graph
    plt.figure(figsize=(8, 6))
    plt.plot(k_values, inertias, marker="o", linestyle="-", color="b")
    plt.title("Elbow Method: Inertia vs. Number of Clusters")
    plt.xlabel("Number of Clusters (K)")
    plt.ylabel("Inertia")
    plt.grid()
    plt.show()

    return k_values, inertias

max_k = 10
k_values, inertias = elbow_method(X, max_k=max_k)

clusters = len(np.unique(y))
print(clusters)

k = KMeans(K=clusters, max_iters=150, plot_steps=True)
y_pred = k.predict(X)

k.plot()

SVM ========================================================================

# SVM from scratch
class SVM:
    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):
        self.lr = learning_rate
        self.lambda_param = lambda_param
        self.n_iters = n_iters
        self.w = None
        self.b = None

    def fit(self, X, y):
        n_samples, n_features = X.shape

        y_ = np.where(y <= 0, -1, 1)

        self.w = np.zeros(n_features)
        self.b = 0

        for _ in range(self.n_iters):
            for idx, x_i in enumerate(X):
                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1
                if condition:
                    self.w -= self.lr * (2 * self.lambda_param * self.w)
                else:
                    self.w -= self.lr * (
                        2 * self.lambda_param * self.w - np.dot(x_i, y_[idx])
                    )
                    self.b -= self.lr * y_[idx]

    def predict(self, X):
        approx = np.dot(X, self.w) - self.b
        return np.sign(approx)

def visualize_svm():
    def get_hyperplane_value(x, w, b, offset):
        return (-w[0] * x + b + offset) / w[1]

    fig = plt.figure()
    ax = fig.add_subplot(1, 1, 1)
    plt.scatter(X[:, 0], X[:, 1], marker="o", c=y)

    x0_1 = np.amin(X[:, 0])
    x0_2 = np.amax(X[:, 0])

    x1_1 = get_hyperplane_value(x0_1, clf.w, clf.b, 0)
    x1_2 = get_hyperplane_value(x0_2, clf.w, clf.b, 0)

    x1_1_m = get_hyperplane_value(x0_1, clf.w, clf.b, -1)
    x1_2_m = get_hyperplane_value(x0_2, clf.w, clf.b, -1)

    x1_1_p = get_hyperplane_value(x0_1, clf.w, clf.b, 1)
    x1_2_p = get_hyperplane_value(x0_2, clf.w, clf.b, 1)

    ax.plot([x0_1, x0_2], [x1_1, x1_2], "y--")
    ax.plot([x0_1, x0_2], [x1_1_m, x1_2_m], "k")
    ax.plot([x0_1, x0_2], [x1_1_p, x1_2_p], "k")

    x1_min = np.amin(X[:, 1])
    x1_max = np.amax(X[:, 1])
    ax.set_ylim([x1_min - 3, x1_max + 3])

    plt.show()

clf = SVM()
clf.fit(X_train, y_train)

print(clf.w, clf.b)
visualize_svm()

def accuracy(y_true, y_pred):
    accuracy = np.sum(y_true == y_pred) / len(y_true)
    return accuracy

predictions = clf.predict(X_test)
print("SVM classification accuracy", accuracy(y_test, predictions))

Decision Tree =================================================================================

# Decision Tree from scratch
from collections import Counter

import numpy as np


def entropy(y):
    hist = np.bincount(y)
    ps = hist / len(y)
    return -np.sum([p * np.log2(p) for p in ps if p > 0])


class Node:
    def __init__(
        self, feature=None, threshold=None, left=None, right=None, *, value=None
    ):
        self.feature = feature
        self.threshold = threshold
        self.left = left
        self.right = right
        self.value = value

    def is_leaf_node(self):
        return self.value is not None


class DecisionTree:
    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None):
        self.min_samples_split = min_samples_split
        self.max_depth = max_depth
        self.n_feats = n_feats
        self.root = None

    def fit(self, X, y):
        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])
        self.root = self._grow_tree(X, y)

    def predict(self, X):
        return np.array([self._traverse_tree(x, self.root) for x in X])

    def _grow_tree(self, X, y, depth=0):
        n_samples, n_features = X.shape
        n_labels = len(np.unique(y))

        # stopping criteria
        if (
            depth >= self.max_depth
            or n_labels == 1
            or n_samples < self.min_samples_split
        ):
            leaf_value = self._most_common_label(y)
            return Node(value=leaf_value)

        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)

        # greedily select the best split according to information gain
        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)

        # grow the children that result from the split
        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)
        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)
        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)
        return Node(best_feat, best_thresh, left, right)

    def _best_criteria(self, X, y, feat_idxs):
        best_gain = -1
        split_idx, split_thresh = None, None
        for feat_idx in feat_idxs:
            X_column = X[:, feat_idx]
            thresholds = np.unique(X_column)
            for threshold in thresholds:
                gain = self._information_gain(y, X_column, threshold)

                if gain > best_gain:
                    best_gain = gain
                    split_idx = feat_idx
                    split_thresh = threshold

        return split_idx, split_thresh

    def _information_gain(self, y, X_column, split_thresh):
        # parent loss
        parent_entropy = entropy(y)

        # generate split
        left_idxs, right_idxs = self._split(X_column, split_thresh)

        if len(left_idxs) == 0 or len(right_idxs) == 0:
            return 0

        # compute the weighted avg. of the loss for the children
        n = len(y)
        n_l, n_r = len(left_idxs), len(right_idxs)
        e_l, e_r = entropy(y[left_idxs]), entropy(y[right_idxs])
        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r

        # information gain is difference in loss before vs. after split
        ig = parent_entropy - child_entropy
        return ig

    def _split(self, X_column, split_thresh):
        left_idxs = np.argwhere(X_column <= split_thresh).flatten()
        right_idxs = np.argwhere(X_column > split_thresh).flatten()
        return left_idxs, right_idxs

    def _traverse_tree(self, x, node):
        if node.is_leaf_node():
            return node.value

        if x[node.feature] <= node.threshold:
            return self._traverse_tree(x, node.left)
        return self._traverse_tree(x, node.right)

    def _most_common_label(self, y):
        counter = Counter(y)
        most_common = counter.most_common(1)[0][0]
        return most_common


if __name__ == "__main__":
    # Imports
    from sklearn import datasets
    from sklearn.model_selection import train_test_split

    def accuracy(y_true, y_pred):
        accuracy = np.sum(y_true == y_pred) / len(y_true)
        return accuracy

    data = datasets.load_breast_cancer()
    X, y = data.data, data.target

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=1234
    )

    clf = DecisionTree(max_depth=10)
    clf.fit(X_train, y_train)

    y_pred = clf.predict(X_test)
    acc = accuracy(y_test, y_pred)

    print("Accuracy:", acc)

Linear Regression =================================================================================

import numpy as np


def r2_score(y_true, y_pred):
    corr_matrix = np.corrcoef(y_true, y_pred)
    corr = corr_matrix[0, 1]
    return corr ** 2


class LinearRegression:
    def __init__(self, learning_rate=0.001, n_iters=1000):
        self.lr = learning_rate
        self.n_iters = n_iters
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        n_samples, n_features = X.shape

        # init parameters
        self.weights = np.zeros(n_features)
        self.bias = 0

        # gradient descent
        for _ in range(self.n_iters):
            y_predicted = np.dot(X, self.weights) + self.bias
            # compute gradients
            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))
            db = (1 / n_samples) * np.sum(y_predicted - y)

            # update parameters
            self.weights -= self.lr * dw
            self.bias -= self.lr * db

    def predict(self, X):
        y_approximated = np.dot(X, self.weights) + self.bias
        return y_approximated


# Testing
if __name__ == "__main__":
    # Imports
    import matplotlib.pyplot as plt
    from sklearn.model_selection import train_test_split
    from sklearn import datasets

    def mean_squared_error(y_true, y_pred):
        return np.mean((y_true - y_pred) ** 2)

    X, y = datasets.make_regression(
        n_samples=100, n_features=1, noise=20, random_state=4
    )

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=1234
    )

    regressor = LinearRegression(learning_rate=0.01, n_iters=1000)
    regressor.fit(X_train, y_train)
    predictions = regressor.predict(X_test)

    mse = mean_squared_error(y_test, predictions)
    print("MSE:", mse)

    accu = r2_score(y_test, predictions)
    print("Accuracy:", accu)

    y_pred_line = regressor.predict(X)
    cmap = plt.get_cmap("viridis")
    fig = plt.figure(figsize=(8, 6))
    m1 = plt.scatter(X_train, y_train, color=cmap(0.9), s=10)
    m2 = plt.scatter(X_test, y_test, color=cmap(0.5), s=10)
    plt.plot(X, y_pred_line, color="black", linewidth=2, label="Prediction")
    plt.show()

Logistic Regression ==============================================================================

import numpy as np


class LogisticRegression:
    def __init__(self, learning_rate=0.001, n_iters=1000):
        self.lr = learning_rate
        self.n_iters = n_iters
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        n_samples, n_features = X.shape

        # init parameters
        self.weights = np.zeros(n_features)
        self.bias = 0

        # gradient descent
        for _ in range(self.n_iters):
            # approximate y with linear combination of weights and x, plus bias
            linear_model = np.dot(X, self.weights) + self.bias
            # apply sigmoid function
            y_predicted = self._sigmoid(linear_model)

            # compute gradients
            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))
            db = (1 / n_samples) * np.sum(y_predicted - y)
            # update parameters
            self.weights -= self.lr * dw
            self.bias -= self.lr * db

    def predict(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        y_predicted = self._sigmoid(linear_model)
        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]
        return np.array(y_predicted_cls)

    def _sigmoid(self, x):
        return 1 / (1 + np.exp(-x))


# Testing
if __name__ == "__main__":
    # Imports
    from sklearn.model_selection import train_test_split
    from sklearn import datasets

    def accuracy(y_true, y_pred):
        accuracy = np.sum(y_true == y_pred) / len(y_true)
        return accuracy

    bc = datasets.load_breast_cancer()
    X, y = bc.data, bc.target

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=1234
    )

    regressor = LogisticRegression(learning_rate=0.0001, n_iters=1000)
    regressor.fit(X_train, y_train)
    predictions = regressor.predict(X_test)

    print("LR classification accuracy:", accuracy(y_test, predictions))

Naive Bayes ========================================================================

import numpy as np


class NaiveBayes:
    def fit(self, X, y):
        n_samples, n_features = X.shape
        self._classes = np.unique(y)
        n_classes = len(self._classes)

        # calculate mean, var, and prior for each class
        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)
        self._var = np.zeros((n_classes, n_features), dtype=np.float64)
        self._priors = np.zeros(n_classes, dtype=np.float64)

        for idx, c in enumerate(self._classes):
            X_c = X[y == c]
            self._mean[idx, :] = X_c.mean(axis=0)
            self._var[idx, :] = X_c.var(axis=0)
            self._priors[idx] = X_c.shape[0] / float(n_samples)

    def predict(self, X):
        y_pred = [self._predict(x) for x in X]
        return np.array(y_pred)

    def _predict(self, x):
        posteriors = []

        # calculate posterior probability for each class
        for idx, c in enumerate(self._classes):
            prior = np.log(self._priors[idx])
            posterior = np.sum(np.log(self._pdf(idx, x)))
            posterior = prior + posterior
            posteriors.append(posterior)

        # return class with highest posterior probability
        return self._classes[np.argmax(posteriors)]

    def _pdf(self, class_idx, x):
        mean = self._mean[class_idx]
        var = self._var[class_idx]
        numerator = np.exp(-((x - mean) ** 2) / (2 * var))
        denominator = np.sqrt(2 * np.pi * var)
        return numerator / denominator


# Testing
if __name__ == "__main__":
    # Imports
    from sklearn.model_selection import train_test_split
    from sklearn import datasets

    def accuracy(y_true, y_pred):
        accuracy = np.sum(y_true == y_pred) / len(y_true)
        return accuracy

    X, y = datasets.make_classification(
        n_samples=1000, n_features=10, n_classes=2, random_state=123
    )
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=123
    )

    nb = NaiveBayes()
    nb.fit(X_train, y_train)
    predictions = nb.predict(X_test)

    print("Naive Bayes classification accuracy", accuracy(y_test, predictions))

PCA ==========================================================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.datasets import load_iris
iris = load_iris()

df = pd.DataFrame(iris.data, columns=iris['feature_names'])
df['iris type'] = iris.target
df['iris name'] = df['iris type'].apply(lambda x: 'sentosa' if x==0 else ('versicolor' if x==1 else 'virginica'))
df.sample(5)

X = iris['data']
y = iris['target']

class MyPCA:
    def __init__(self):
        self.mean = 0
        self.stdev = 0
        self.cov_mat = None
        self.eigvals = None
        self.eigvecs = None

    # train and transform
    def fit_transform(self, x, k=2):
        x = self.__standardize(x)
        self.__compute_covarience(x)
        self.__compute_eigenpair()

        # transform
        comp = self.eigvecs[:k]
        x_new = x.dot(comp.T)
        return x_new

    # plot heatmap of covariance matrix
    def plot_cov(self):
        sns.heatmap(self.cov_mat, annot=True)
        plt.plot()

    # plot explained varience
    def plot_variance(self):
        eigval_total = sum(self.eigvals)
        explained_variance = [(i / eigval_total)*100 for i in self.eigvals]
        explained_variance = np.round(explained_variance, 2)
        cum_explained_variance = np.cumsum(explained_variance)
        
        print('Explained variance: {}'.format(explained_variance))
        print('Cumulative explained variance: {}'.format(cum_explained_variance))

        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.grid(True)
        plt.bar(np.arange(1,X.shape[1]+1), explained_variance)
        plt.xticks(np.arange(1,X.shape[1]+1))
        plt.xlabel('Number of components')
        plt.ylabel('Explained variance');
        
        plt.subplot(1, 2, 2)
        plt.grid(True)
        plt.plot(np.arange(1,X.shape[1]+1), cum_explained_variance, '-o')
        plt.xticks(np.arange(1,X.shape[1]+1))
        plt.xlabel('Number of components')
        plt.ylabel('Cumulative explained variance');
        plt.show()

    # standardize the data
    def __standardize(self, x):
        self.mean = np.mean(x, axis=0)
        self.stdev = np.std(x, axis=0)
        x = (x - self.mean) / self.stdev
        return x

    # compute covariance matrix
    def __compute_covarience(self, x):
        self.cov_mat = np.cov(x.T)

    # compute eigenvalues & eigenvectors
    def __compute_eigenpair(self):
        self.eigvals, self.eigvecs = np.linalg.eig(self.cov_mat)
        self.eigvecs = self.eigvecs.T
        
        # sorting eigenvalues & corresponding eigenvectors in decreasing order
        idx = np.argsort(self.eigvals)[::-1]
        self.eigvals = self.eigvals[idx]
        self.eigvecs = self.eigvecs[idx]

pca = MyPCA()

X_new = pca.fit_transform(X, 2)

# plot transformed data
plt.scatter(X_new[:, 0], X_new[:, 1], c = y)
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.show()

pca.plot_variance()

pca.plot_variance()

SVD =================================================================================

import numpy as np
import matplotlib.pyplot as plt
import cv2

# SVD from scratch function
def my_svd(A):
    # compute A^T * A
    AtA = np.dot(A.T, A)
    
    # eigen decomposition of A^T * A to get eigenvalues & eigenvectors
    eigvals, eigvecs = np.linalg.eig(AtA)
    
    # sort eigenvalues and corresponding eigenvectors in decreasing order
    idx = np.argsort(eigvals)[::-1]
    eigvals = eigvals[idx]
    eigvecs = eigvecs[:, idx]
    
    # compute singular values from eigenvalues
    singular_values = np.sqrt(eigvals)
    
    # compute U using the formula U = A * V * S^(-1)
    U = np.zeros((A.shape[0], A.shape[0]), dtype=float)
    for i in range(len(singular_values)):
        U[:, i] = np.dot(A, eigvecs[:, i]) / singular_values[i]

    # fill singular values diagonally to get Sigma
    S = np.zeros((U.shape[0], eigvecs.shape[1]), dtype=float)
    for i in range(len(singular_values)):
        S[i, i] = singular_values[i]

    return U, S, eigvecs.T

# load gray image
img = cv2.imread('datasets/SasukeUchiha.jpg', cv2.IMREAD_GRAYSCALE).astype(float)
img /= 255.0    # normalize in range [0, 1]
img.shape

# dispaly gray image
plt.figure(figsize=(5,3))
plt.imshow(img, cmap='gray')
plt.axis('off')
plt.show()

# decompose image using SVD
U, S, Vt = my_svd(img)

# reconstruct image with different level of compression
i = 1
for k in [5, 25, 50, 100, 250, 512]:
    img2 = np.dot(U[:, :k], np.dot(S[:k, :k], Vt[:k, :]))    # A = U * S * V.T
    # rescale to range [0, 255]
    img2 *= 255.0
    img2 = np.clip(img2, 0, 255).astype(np.uint8)

    plt.subplot(2, 3, i)
    i += 1
    plt.imshow(img2, cmap='gray')
    plt.title(f'k = {k}')
    plt.axis('off')
plt.show()

total_variance = np.sum(S**2) #Total sum of squared singular values
variance_ratios = []

for i in range(5, 512, 20):
    # Calculate the variance captured by the first i singular values
    captured_variance = np.sum(S[:i]**2)  # Sum of squared singular values
    variance_ratio = captured_variance / total_variance  # Proportion of total variance
    variance_ratios.append(variance_ratio)

plt.plot(range(5, 512, 20), variance_ratios, marker='o')
plt.xlabel('Number of Singular Values')
plt.ylabel('Variance Captured')
plt.title('Variance Captured by Each Number of Singular Values')
plt.grid(True)
plt.show()